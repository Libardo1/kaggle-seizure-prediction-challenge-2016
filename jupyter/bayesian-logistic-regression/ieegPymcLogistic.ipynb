{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting:ieegFeatures:2016-10-31 18:41:36.239124\n",
      "Cols:1239\n",
      "1239\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "dirToInclude=parentdir +'/features/'\n",
    "sys.path.insert(0,dirToInclude)\n",
    "\n",
    "\n",
    "import IeegConsts\n",
    "from IeegConsts import *\n",
    "from IeegFeatures import *\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=4, threshold=10000, linewidth=100, edgeitems=999, suppress=True)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('precision', 6)\n",
    "    \n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train_dir=TRAIN_DATA_FOLDER_IN_ALL\n",
    "test_dir=TEST_DATA_FOLDER_IN_ALL    \n",
    "\n",
    "ieegFeatures= IeegFeatures(train_dir, True)\n",
    "df_cols_train=ieegFeatures.ieegGenCols()\n",
    "print len(df_cols_train)\n",
    "F_NAME_TRAIN= TRAIN_FEAT_BASE + TRAIN_PREFIX_ALL +'-feat_TRAIN_df.csv'\n",
    "X_df_train=pandas.read_csv(F_NAME_TRAIN, engine='python') \n",
    "X_df_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def dropBadFiles(df):\n",
    "    print df.shape    \n",
    "\n",
    "    s1 = ['1_137_0.mat', '1_138_0.mat', '1_139_0.mat', '1_140_0.mat', '1_141_0.mat', '1_142_0.mat', '1_166_0.mat', '1_167_0.mat', '1_168_0.mat', '1_169_0.mat', '1_170_0.mat',\n",
    "          '1_171_0.mat', '1_266_0.mat', '1_267_0.mat', '1_268_0.mat', '1_269_0.mat', '1_270_0.mat', '1_271_0.mat', '1_303_0.mat', '1_304_0.mat', '1_305_0.mat', '1_306_0.mat',\n",
    "          '1_307_0.mat', '1_308_0.mat', '1_397_0.mat', '1_398_0.mat', '1_399_0.mat', '1_400_0.mat', '1_401_0.mat', '1_402_0.mat', '1_412_0.mat', '1_413_0.mat', '1_414_0.mat',\n",
    "          '1_415_0.mat', '1_416_0.mat', '1_417_0.mat', '1_481_0.mat', '1_482_0.mat', '1_483_0.mat', '1_484_0.mat', '1_485_0.mat', '1_486_0.mat', '1_520_0.mat', '1_521_0.mat',\n",
    "          '1_522_0.mat', '1_523_0.mat', '1_524_0.mat', '1_525_0.mat', '1_585_0.mat', '1_586_0.mat', '1_587_0.mat', '1_588_0.mat', '1_589_0.mat', '1_590_0.mat', '1_621_0.mat',\n",
    "          '1_622_0.mat', '1_623_0.mat', '1_624_0.mat', '1_625_0.mat', '1_626_0.mat', '1_703_0.mat', '1_704_0.mat', '1_705_0.mat', '1_706_0.mat', '1_707_0.mat', '1_708_0.mat',\n",
    "          '1_784_0.mat', '1_785_0.mat', '1_786_0.mat', '1_787_0.mat', '1_788_0.mat', '1_789_0.mat', '1_855_0.mat', '1_856_0.mat', '1_857_0.mat', '1_858_0.mat', '1_859_0.mat',\n",
    "          '1_860_0.mat', '1_985_0.mat', '1_986_0.mat', '1_987_0.mat', '1_988_0.mat', '1_989_0.mat', '1_990_0.mat', '1_1015_0.mat', '1_1016_0.mat', '1_1017_0.mat', '1_1018_0.mat',\n",
    "          '1_1019_0.mat', '1_1020_0.mat', '1_1099_0.mat', '1_1100_0.mat', '1_1101_0.mat', '1_1102_0.mat', '1_1103_0.mat', '1_1104_0.mat', '1_1129_0.mat', '1_1130_0.mat', '1_1131_0.mat',\n",
    "          '1_1133_0.mat', '1_1134_0.mat']\n",
    "\n",
    "    s2 = ['2_69_0.mat', '2_70_0.mat', '2_71_0.mat', '2_72_0.mat', '2_399_0.mat', '2_400_0.mat', '2_401_0.mat', '2_402_0.mat', '2_439_0.mat', '2_440_0.mat', '2_441_0.mat',\n",
    "          '2_442_0.mat', '2_443_0.mat', '2_444_0.mat', '2_452_0.mat', '2_453_0.mat', '2_454_0.mat', '2_455_0.mat', '2_456_0.mat', '2_531_0.mat', '2_532_0.mat', '2_533_0.mat',\n",
    "          '2_534_0.mat', '2_763_0.mat', '2_764_0.mat', '2_765_0.mat', '2_766_0.mat', '2_767_0.mat', '2_768_0.mat', '2_1427_0.mat', '2_1428_0.mat', '2_1429_0.mat', '2_1430_0.mat',\n",
    "          '2_1431_0.mat', '2_1432_0.mat', '2_1603_0.mat', '2_1604_0.mat', '2_1605_0.mat', '2_1763_0.mat', '2_1764_0.mat', '2_1765_0.mat', '2_1766_0.mat', '2_1767_0.mat', '2_2119_0.mat',\n",
    "          '2_2120_0.mat', '2_2121_0.mat', '2_2122_0.mat', '2_2123_0.mat', '2_2124_0.mat']\n",
    "\n",
    "    s3 = ['3_799_0.mat', '3_901_0.mat', '3_902_0.mat', '3_903_0.mat', '3_904_0.mat', '3_905_0.mat', '3_906_0.mat',\n",
    "          '3_1105_0.mat', '3_1106_0.mat', '3_1107_0.mat', '3_1108_0.mat']\n",
    "    \n",
    "    for item in s1:\n",
    "        print 'droping:' + item\n",
    "        df = df.drop(df[df.file == item].index)\n",
    "\n",
    "    for item in s2:\n",
    "        print 'droping:' + item\n",
    "        df = df.drop(df[df.file == item].index)\n",
    "\n",
    "    for item in s3:\n",
    "        print 'droping:' + item\n",
    "        df = df.drop(df[df.file == item].index)\n",
    "\n",
    "    print 'Final shape:' + str(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "last_cols=list()\n",
    "for i in range(1, 160 + 1):\n",
    "    last_cols.append('psd_{}'.format(i))    \n",
    "for i in range(1, 16 + 1):\n",
    "    last_cols.append('var_{}'.format(i))    \n",
    "for i in range(1, 16 + 1):\n",
    "    last_cols.append('kurt_{}'.format(i))\n",
    "for i in range(1, n_corr_coeff + 1):\n",
    "    last_cols.append('corcoef_{}'.format(i))\n",
    "    # for i in range(1, n + 1):\n",
    "    #     cols.append('hurst_{}'.format(i))\n",
    "for i in range(1,  n_plv+ 1):\n",
    "    last_cols.append('plv_{}'.format(i))    \n",
    "\n",
    "        \n",
    "# X_df_train_SINGLE=X_df_train\n",
    "# X_df_train_SINGLE = dropBadFiles(X_df_train)\n",
    "\n",
    "# answers_1_SINGLE = list (X_df_train_SINGLE[singleResponseVariable].values)\n",
    "# X_df_train_SINGLE = X_df_train_SINGLE.drop(singleResponseVariable, axis=1)\n",
    "# X_df_train_SINGLE.drop('id', axis=1, inplace=True)\n",
    "# X_df_train_SINGLE.drop('file', axis=1, inplace=True)\n",
    "# X_df_train_SINGLE.drop('patient_id', axis=1, inplace=True)\n",
    "# X_df_train_SINGLE.drop('file_size', axis=1, inplace=True)\n",
    "# X_df_train_SINGLE.drop('sequence_id', axis=1, inplace=True)\n",
    "# X_df_train_SINGLE.drop('segment', axis=1, inplace=True)\n",
    "\n",
    "# X_df_train_SINGLE=X_df_train_SINGLE[last_cols]\n",
    "# X_df_train_SINGLE=X_df_train_SINGLE.apply(lambda x: pandas.to_numeric(x, errors='ignore'))\n",
    "\n",
    "\n",
    "# # Build pasty expression -- feed best features automatically \n",
    "# s='result ~ '\n",
    "\n",
    "# last_cols=['corcoef_101', 'corcoef_106', 'corcoef_114', 'corcoef_24', 'corcoef_30', 'corcoef_42', 'corcoef_43', 'corcoef_54', 'corcoef_57', 'corcoef_67', 'corcoef_78', 'psd_103', 'psd_105', 'psd_132', 'psd_142', 'psd_145', 'psd_151', 'psd_152', 'psd_35', 'psd_36', 'psd_45', 'psd_81', 'psd_97', 'psd_98', 'var_1', 'var_11', 'var_16', 'var_3', 'var_4', 'var_9']\n",
    "# for item in last_cols:\n",
    "#     s += item + ' + '\n",
    "# s=s[:-2]\n",
    "# print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting:ieegFeatures:2016-10-15 18:26:40.611235\n",
      "Cols:559\n",
      "559\n",
      "Iteration:0\n"
     ]
    }
   ],
   "source": [
    "# Pymc expects an R like Df, so the response variable must be included\n",
    "ieegFeatures= IeegFeatures(train_dir, True)\n",
    "df_cols_train=ieegFeatures.ieegGenCols()\n",
    "print len(df_cols_train)\n",
    "F_NAME_TRAIN= TRAIN_FEAT_BASE + TRAIN_PREFIX_ALL +'-feat_TRAIN_df.csv'\n",
    "X_df_train=pandas.read_csv(F_NAME_TRAIN, engine='python') \n",
    "X_df_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "X_df_train_SINGLE=X_df_train\n",
    "_df_train_SINGLE = dropBadFiles(X_df_train)\n",
    "\n",
    "X_df_train_SINGLE.drop('id', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('file', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('patient_id', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('file_size', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('sequence_id', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('segment', axis=1, inplace=True)\n",
    "# X_df_train_SINGLE=X_df_train_SINGLE[last_cols]\n",
    "X_df_train_SINGLE=X_df_train_SINGLE.apply(lambda x: pandas.to_numeric(x, errors='ignore'))\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "def fastPredict(new_observation, theta, intercept):    \n",
    "    v =  intercept + np.einsum('j,j->',new_observation, theta)    \n",
    "    return expit(v)\n",
    "\n",
    "def plot_traces(traces, retain=1000):    \n",
    "    ax = pm.traceplot(traces[-retain:], figsize=(12,len(traces.varnames)*1.5),\n",
    "        lines={k: v['mean'] for k, v in pm.df_summary(traces[-retain:]).iterrows()})\n",
    "\n",
    "    for i, mn in enumerate(pm.df_summary(traces[-retain:])['mean']):\n",
    "        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n",
    "                    ,xytext=(5,10), textcoords='offset points', rotation=90\n",
    "                    ,va='bottom', fontsize='large', color='#AA0022')\n",
    "        \n",
    "# import pymc3 as pm\n",
    "import pymc3\n",
    "from pymc3.glm import glm\n",
    "from pymc3.glm.families import Binomial\n",
    "\n",
    "niter=200000\n",
    "i=0\n",
    "with pymc3.Model() as logistic_model:\n",
    "    pymc3.glm.glm(s, X_df_train_SINGLE, family=pymc3.glm.families.Binomial())\n",
    "    print 'Iteration:' + str(i)\n",
    "    i=i+1\n",
    "    step = pymc3.NUTS()\n",
    "    trace_logistic_model = pymc3.sample(niter, step=step,progressbar=True)    \n",
    "    \n",
    "# predict\n",
    "df_trace_logistic_model = pm.trace_to_dataframe(trace_logistic_model[niter//2:])\n",
    "w_theta = df_trace_logistic_model[last_cols].mean(0)\n",
    "df_trace_logistic_model.to_csv(\"df_trace_logistic_model.csv\")\n",
    "w_theta.to_csv(\"w_theta.csv\")\n",
    "w_intercept=df_trace_logistic_model['Intercept'].mean(0)\n",
    "\n",
    "print w_theta\n",
    "print w_intercept \n",
    "plot_traces(trace_logistic_model, retain=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting:ieegFeatures:2016-09-22 16:51:05.199385\n",
      "Cols:499\n",
      "499\n",
      "('Writing submission: ', 'submissionmcmc_all_5022016-09-22-16-51.csv')\n",
      "('Done writing submission: ', 'submissionmcmc_all_5022016-09-22-16-51.csv')\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def fastPredict(new_observation, theta, intercept):    \n",
    "    v =  intercept + np.einsum('j,j->',new_observation, theta)    \n",
    "    return expit(v)\n",
    "\n",
    "\n",
    "test_dir=TEST_DATA_FOLDER_IN_ALL\n",
    "ieegFeatures= IeegFeatures(test_dir, False)\n",
    "df_cols_test=ieegFeatures.ieegGenCols()\n",
    "print len(df_cols_test)\n",
    "F_NAME_TEST= TEST_FEAT_BASE + TEST_PREFIX_ALL +'-feat_TEST_df.csv'\n",
    "X_df_TEST=pandas.read_csv(F_NAME_TEST, engine='python') \n",
    "X_df_TEST.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# X_df_TEST.drop('id', axis=1, inplace=True)\n",
    "X_df_TEST.drop('file', axis=1, inplace=True)\n",
    "X_df_TEST.drop('patient_id', axis=1, inplace=True)\n",
    "# X_df_TEST.drop('file_size', axis=1, inplace=True)\n",
    "# X_df_TEST.drop('sequence_id', axis=1, inplace=True)\n",
    "X_df_TEST.head(3)\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "now = datetime.now()\n",
    "import dis\n",
    "sub_file = 'submission' + '_mcmc_'  + str(len(glm_factor)) + '_' + str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "r= pandas.DataFrame.from_csv('sample_submission.csv')\n",
    "print('Writing submission: ', sub_file)\n",
    "f = open(sub_file, 'w') # append mode\n",
    "f.write('File,Class\\n')\n",
    "total = 0\n",
    "\n",
    "for index, row in r.iterrows():            \n",
    "    id_str= index     \n",
    "    arr = id_str.split(\"_\")\n",
    "    patient = int(arr[0])        \n",
    "    new_id= ieegFeatures.getIdFromFileName(id_str) \n",
    "#     print str(new_id)\n",
    "    \n",
    "    X_df_single_row=X_df_TEST.loc[X_df_TEST['id'] == new_id]\n",
    "    X_df_single_row.drop('id', axis=1, inplace=True)\n",
    "    X_df_single_row= X_df_single_row[glm_factor]        \n",
    "#     X_df_single_row.drop('file', axis=1, inplace=True)\n",
    "#     X_df_single_row.drop('patient_id', axis=1, inplace=True)                    \n",
    "    X_df_single_row = np.asarray(X_df_single_row)        \n",
    "    c_pred= fastPredict(tuple (X_df_single_row)[0]),w_intercept, w_theta))\n",
    "    str1 = id_str + ',' + str(predict (tuple (X_df_single_row)[0])) + '\\n'  \n",
    "#     print str1\n",
    "    \n",
    "    f.write(str1)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print('Done writing submission: ', sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}