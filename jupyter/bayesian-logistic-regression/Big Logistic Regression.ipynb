{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/freebsd/Library/Python/2.7/lib/python/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting:ieegFeatures:2016-11-10 19:53:01.550337\n",
      "Cols:1239\n",
      "1239\n",
      "(5971, 1239)\n",
      "Start shape:(5971, 1239)\n",
      "Final shape:(4699, 1239)\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "dirToInclude=parentdir +'/features/'\n",
    "sys.path.insert(0,dirToInclude)\n",
    "\n",
    "import IeegConsts\n",
    "from IeegConsts import *\n",
    "from IeegFeatures import *\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=4, threshold=10000, linewidth=100, edgeitems=999, suppress=True)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('precision', 6)\n",
    "    \n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train_dir=TRAIN_DATA_FOLDER_IN_ALL\n",
    "test_dir=TEST_DATA_FOLDER_IN_ALL    \n",
    "\n",
    "\n",
    "def dropBadFiles(df):\n",
    "    print df.shape\n",
    "    bad_files = pandas.read_csv(\"train_and_test_data_labels_safe.csv\", engine='python')\n",
    "\n",
    "    print 'Start shape:' + str(df.shape)\n",
    "    for index, row in bad_files.iterrows():\n",
    "        safe = str(row['safe'])  # file name\n",
    "        if safe=='0':\n",
    "            f_name = row['image']  # file name\n",
    "            # print 'droping:' + str(f_name)\n",
    "            df = df.drop(df[df.file ==f_name].index)\n",
    "\n",
    "    print 'Final shape:' + str(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "ieegFeatures= IeegFeatures(train_dir, True)\n",
    "df_cols_train=ieegFeatures.ieegGenCols()\n",
    "print len(df_cols_train)\n",
    "F_NAME_TRAIN= TRAIN_FEAT_BASE + TRAIN_PREFIX_ALL +'-feat_TRAIN_df.csv'\n",
    "X_df_train=pandas.read_csv(F_NAME_TRAIN, engine='python') \n",
    "X_df_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "n=16\n",
    "last_cols=list()\n",
    "for i in range(1, n_psd + 1):\n",
    "    last_cols.append('psd_{}'.format(i))    \n",
    "for i in range(1, 16 + 1):\n",
    "    last_cols.append('var_{}'.format(i))    \n",
    "for i in range(1, 16 + 1):\n",
    "    last_cols.append('kurt_{}'.format(i))\n",
    "for i in range(1, n_corr_coeff + 1):\n",
    "    last_cols.append('corcoef_{}'.format(i))\n",
    "for i in range(1, n + 1):\n",
    "    last_cols.append('hurst_{}'.format(i))\n",
    "# for i in range(1,  n_plv+ 1):\n",
    "#     last_cols.append('plv_{}'.format(i))    \n",
    "# for i in range(1, n + 1):\n",
    "#     last_cols.append('mean_{}'.format(i))\n",
    "# for i in range(1, n + 1):\n",
    "#     last_cols.append('median_{}'.format(i))\n",
    "# for i in range(1, n + 1):\n",
    "#     last_cols.append('std_{}'.format(i))\n",
    "\n",
    "X_df_train_SINGLE=X_df_train\n",
    "X_df_train_SINGLE = dropBadFiles(X_df_train)\n",
    "\n",
    "\n",
    "X_df_train_SINGLE.drop('id', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('file', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('patient_id', axis=1, inplace=True)\n",
    "\n",
    "X_df_train_SINGLE = X_df_train_SINGLE.loc[X_df_train_SINGLE['file_size'] > 100000]\n",
    "X_df_train_SINGLE.drop('file_size', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('sequence_id', axis=1, inplace=True)\n",
    "X_df_train_SINGLE.drop('segment', axis=1, inplace=True)\n",
    "\n",
    "answers_1_SINGLE = list (X_df_train_SINGLE[singleResponseVariable].values)\n",
    "X_df_train_SINGLE = X_df_train_SINGLE.drop(singleResponseVariable, axis=1)\n",
    "\n",
    "X_df_train_SINGLE=X_df_train_SINGLE[last_cols]\n",
    "X_df_train_SINGLE=X_df_train_SINGLE.apply(lambda x: pandas.to_numeric(x, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=answers_1_SINGLE\n",
    "X=X_df_train_SINGLE\n",
    "\n",
    "lr_best_params = {'penalty': 'l2', 'C': 100, 'solver': 'newton-cg', 'fit_intercept': False}\n",
    "lr = LogisticRegression(**lr_best_params)\n",
    "lr.fit(X, y)\n",
    "#Store LR coeefs\n",
    "lr_coeefs=lr.coef_        \n",
    "\n",
    "k = (X_df_train_SINGLE.shape[1])\n",
    "import theano.tensor as tt\n",
    "invlogit = lambda x: 1/(1 + tt.exp(-x))\n",
    "with pm.Model() as logistic_model:        \n",
    "    b = pm.Normal('b', 0.0, sd=10000, shape=k)    \n",
    "    p = invlogit(tt.dot(X, b))    \n",
    "    likelihood = pm.Bernoulli('likelihood', p, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc.graph\n",
    "graph = pymc.graph.graph(logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_powell\n",
    "niter=30000\n",
    "with logistic_model:\n",
    "#     start_MAP = pm.find_MAP(fmin=fmin_powell, disp=True)\n",
    "#     print start_MAP\n",
    "#     start_MAP=lr_coeefs\n",
    "    step = pm.NUTS()\n",
    "    step=pm.Metropolis()\n",
    "    trace_logistic_model = pm.sample(niter, step=step, progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6315a07b8bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# last_cols=X_df_train_SINGLE.columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_trace_logistic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_logistic_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_trace_logistic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mw_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_trace_logistic_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pymc3/backends/tracetab.pyc\u001b[0m in \u001b[0;36mtrace_to_dataframe\u001b[0;34m(trace, chains, flat_names)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvarname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mflat_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mvar_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvarname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# predict\n",
    "# last_cols=X_df_train_SINGLE.columns\n",
    "\n",
    "df_trace_logistic_model = pm.trace_to_dataframe(trace_logistic_model[niter//2:])\n",
    "df_trace_logistic_model.columns=last_cols\n",
    "w_theta = df_trace_logistic_model[last_cols].mean(0)\n",
    "# df_trace_logistic_model.to_csv(\"df_trace_logistic_model.csv\")\n",
    "# w_theta.to_csv(\"w_theta.csv\")\n",
    "# w_intercept=df_trace_logistic_model['Intercept'].mean(0)\n",
    "# pm.summary(trace_logistic_model[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_trace_logistic_model.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = pm.traceplot(trace_logistic_model[-1000:], figsize=(12,len(trace_logistic_model.varnames)*1.5),  \n",
    "    lines={k: v['mean'] for k, v in pm.df_summary(trace_logistic_model[-1000:]).iterrows()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "    #       PATIENT ID\n",
    "    # --------------------------------------------------------\n",
    "def getIdFromFileName(id_str):\n",
    "    arr = id_str.split(\"_\")\n",
    "#     print arr\n",
    "    patient = int(arr[1])\n",
    "#     print patient\n",
    "    p_id_str = str(arr[2])\n",
    "#     print p_id_str\n",
    "    p_id = int((p_id_str)[:-4])\n",
    "#     print p_id\n",
    "    new_id = [patient * 100000 + p_id]\n",
    "    return new_id\n",
    "    \n",
    "from scipy.special import expit\n",
    "\n",
    "def fastPredict(new_observation, theta): \n",
    "    v =  np.einsum('j,j->',new_observation, theta)    \n",
    "    return expit(v)\n",
    "\n",
    "\n",
    "test_dir=TEST_DATA_FOLDER_IN_ALL\n",
    "ieegFeatures= IeegFeatures(test_dir, False)\n",
    "df_cols_test=ieegFeatures.ieegGenCols()\n",
    "print len(df_cols_test)\n",
    "F_NAME_TEST= TEST_FEAT_BASE + TEST_PREFIX_ALL +'-feat_TEST_df.csv'\n",
    "X_df_TEST=pandas.read_csv(F_NAME_TEST, engine='python') \n",
    "X_df_TEST.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# X_df_TEST.drop('id', axis=1, inplace=True)\n",
    "X_df_TEST.drop('file', axis=1, inplace=True)\n",
    "X_df_TEST.drop('patient_id', axis=1, inplace=True)\n",
    "# X_df_TEST.drop('file_size', axis=1, inplace=True)\n",
    "# X_df_TEST.drop('sequence_id', axis=1, inplace=True)\n",
    "X_df_TEST.head(3)\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "now = datetime.now()\n",
    "import dis\n",
    "sub_file = 'submission' + '_mcmc_' + str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "\n",
    "r= pandas.DataFrame.from_csv('sample_submission.csv')\n",
    "print('Writing submission: ', sub_file)\n",
    "f = open(sub_file, 'w') # append mode\n",
    "f.write('File,Class\\n')\n",
    "total = 0\n",
    "\n",
    "for index, row in r.iterrows():            \n",
    "    id_str= index     \n",
    "    arr = id_str.split(\"_\")\n",
    "#     print str(arr)\n",
    "#     print str(arr[0])\n",
    "#     print str(arr[1])\n",
    "#     print str(arr[2])\n",
    "    patient = int(arr[1])        \n",
    "    new_id= getIdFromFileName(id_str) \n",
    "#     print str(new_id)\n",
    "    \n",
    "    X_df_single_row=X_df_TEST.loc[X_df_TEST['id'] == new_id]\n",
    "    X_df_single_row.drop('id', axis=1, inplace=True)\n",
    "    X_df_single_row= X_df_single_row[last_cols]        \n",
    "#     X_df_single_row.drop('file', axis=1, inplace=True)\n",
    "#     X_df_single_row.drop('patient_id', axis=1, inplace=True)                    \n",
    "    X_df_single_row = np.asarray(X_df_single_row)        \n",
    "    c_pred= 1.0- fastPredict( (tuple (X_df_single_row)[0]), w_theta)\n",
    "    str1 = id_str + ',' + str(c_pred) + '\\n'  \n",
    "#     print str1\n",
    "    \n",
    "    f.write(str1)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print('Done writing submission: ', sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/ca3eb59c03ade9052d2d2dbcd7345f1b"
  },
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Untitled1.ipynb",
    "public": true
   },
   "id": "ca3eb59c03ade9052d2d2dbcd7345f1b"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0.0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}